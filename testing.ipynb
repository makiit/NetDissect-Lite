{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e890b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a687e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "from loader.model_loader import loadmodel\n",
    "from feature_operation import hook_feature,FeatureOperator\n",
    "from visualize.report import generate_html_summary\n",
    "from util.clean import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea86161",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(settings.DATASET)\n",
    "print(settings.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from torch.autograd import Variable as V\n",
    "from PIL import Image\n",
    "# from scipy.misc import imresize\n",
    "import numpy as np\n",
    "import torch\n",
    "import settings\n",
    "import time\n",
    "import util.upsample as upsample\n",
    "import util.vecquantile as vecquantile\n",
    "import multiprocessing.pool as pool\n",
    "from loader.data_loader import load_csv\n",
    "from loader.data_loader import SegmentationData, SegmentationPrefetcher\n",
    "\n",
    "features_blobs = []\n",
    "start_unit = 180\n",
    "end_unit = 190\n",
    "def hook_feature(module, input, output):\n",
    "#     print(\"Hooking module named \",module.name)\n",
    "    features_blobs.append(output.data.cpu().numpy()[:,start_unit:end_unit,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965067a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "model_file = \"checkpoints/resnet18-200-regular.pth\"\n",
    "# model_file = \"zoo/resnet18_places365.pth.tar\"\n",
    "# path = \"iter200\"\n",
    "# fo = FeatureOperator(path)\n",
    "print(\"Loading model file \",model_file)\n",
    "# model = loadmodel(hook_feature,model_file)\n",
    "# model = loadmodel(hook_feature,model_file)\n",
    "checkpoint = torch.load(model_file)\n",
    "model = torchvision.models.__dict__[settings.MODEL](num_classes=settings.NUM_CLASSES)\n",
    "model.conv1 = torch.nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "model.maxpool = torch.nn.Identity()\n",
    "state_dict = checkpoint\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.data_loader import load_csv\n",
    "import settings\n",
    "from loader.data_loader import SegmentationData, SegmentationPrefetcher\n",
    "print(settings.DATA_DIRECTORY)\n",
    "data = SegmentationData(settings.DATA_DIRECTORY, categories=settings.CATAGORIES)\n",
    "loader = SegmentationPrefetcher(data,categories=['image'],once=True,batch_size=settings.BATCH_SIZE)\n",
    "mean = [109.5388,118.6897,124.6901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = (len(loader.indexes) + loader.batch_size - 1) / loader.batch_size\n",
    "print(num_batches)\n",
    "print(model._modules.get(\"layer4\"))\n",
    "model._modules.get(\"layer4\").register_forward_hook(hook_feature)\n",
    "print(len(loader.indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b57334",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxfeatures = [None] * len(settings.FEATURE_NAMES) #Max activation in the channel (broden_size,no.of channels)\n",
    "wholefeatures = [None] * len(settings.FEATURE_NAMES) #All the activations (broden_size,no.of channels,h,w)\n",
    "features_size = [None] * len(settings.FEATURE_NAMES)\n",
    "memmap=True\n",
    "for batch_idx,batch in enumerate(loader.tensor_batches(bgr_mean=mean)):\n",
    "        del features_blobs[:]\n",
    "        torch.cuda.empty_cache()\n",
    "        input = batch[0]\n",
    "        batch_size = len(input)\n",
    "        print('extracting feature from batch %d / %d' % (batch_idx+1, num_batches))\n",
    "        input = torch.from_numpy(input[:, ::-1, :, :].copy())\n",
    "        input.div_(255.0 * 0.224)\n",
    "        if settings.GPU:\n",
    "            input = input.cuda()\n",
    "        input_var = V(input,volatile=True)\n",
    "        logit = model.forward(input_var)  \n",
    "#         if(batch_idx>2):break\n",
    "        #Initializing the feature variables\n",
    "        print(\"Feature Blobs length \",len(features_blobs))\n",
    "        print(\"First blob\",np.shape(features_blobs[0]))\n",
    "        if maxfeatures[0] is None:\n",
    "            # initialize the feature variable\n",
    "            for i, feat_batch in enumerate(features_blobs):\n",
    "                print(\"Initializing %d\"%i)\n",
    "                size_features = (len(loader.indexes), feat_batch.shape[1])\n",
    "                if memmap:\n",
    "                    maxfeatures[i] = np.memmap('cifar100_actual_Max_features.mmap',dtype=float,mode='w+',shape=size_features)\n",
    "                else:\n",
    "                    maxfeatures[i] = np.zeros(size_features)\n",
    "                    \n",
    "        #Initializing the all feature variable\n",
    "        if len(feat_batch.shape) == 4 and wholefeatures[0] is None:\n",
    "            # initialize the feature variable\n",
    "            for i, feat_batch in enumerate(features_blobs):\n",
    "                size_features = (\n",
    "                len(loader.indexes), feat_batch.shape[1], feat_batch.shape[2], feat_batch.shape[3])\n",
    "                features_size[i] = size_features\n",
    "                if memmap:\n",
    "                    wholefeatures[i] = np.memmap('cifar100_actual_Whole_features.mmap', dtype=float, mode='w+', shape=size_features)\n",
    "                else:\n",
    "                    wholefeatures[i] = np.zeros(size_features)\n",
    "                    \n",
    "        np.save(\"test_feature_size.npy\", features_size)\n",
    "        start_idx = batch_idx*settings.BATCH_SIZE\n",
    "        end_idx = min((batch_idx+1)*settings.BATCH_SIZE, len(loader.indexes))\n",
    "        for i, feat_batch in enumerate(features_blobs):\n",
    "            if len(feat_batch.shape) == 4:\n",
    "                wholefeatures[i][start_idx:end_idx] = feat_batch\n",
    "                maxfeatures[i][start_idx:end_idx] = np.max(np.max(feat_batch,3),2)\n",
    "            elif len(feat_batch.shape) == 3:\n",
    "                maxfeatures[i][start_idx:end_idx] = np.max(feat_batch, 2)\n",
    "            elif len(feat_batch.shape) == 2:\n",
    "                maxfeatures[i][start_idx:end_idx] = feat_batch\n",
    "#     if len(feat_batch.shape) == 2:\n",
    "#         wholefeatures = maxfeatures\n",
    "#     return wholefeatures,maxfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = np.load(\"test_feature_size.npy\")\n",
    "print(feature_size)\n",
    "wholefeatures = np.memmap(\"Places_Whole_features.mmap\", dtype=float,mode='r', shape=tuple(feature_size[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa99b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(wholefeatures))\n",
    "fo = FeatureOperator(\"Places_test\")\n",
    "thresh = fo.quantile_threshold(wholefeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"Test_tally.csv\"\n",
    "features = wholefeatures\n",
    "print(features.shape)\n",
    "units = features.shape[1]\n",
    "print(units)\n",
    "labels = len(data.label)\n",
    "categories = data.category_names()\n",
    "print(categories)\n",
    "tally_both = np.zeros((units,labels),dtype=np.float64)\n",
    "tally_units = np.zeros(units,dtype=np.float64)\n",
    "tally_units_cat = np.zeros((units,len(categories)), dtype=np.float64)\n",
    "tally_labels = np.zeros(labels,dtype=np.float64)\n",
    "print(\"Tally labels\",np.shape(tally_labels))\n",
    "print(\"Tally units\",np.shape(tally_units))\n",
    "print(\"Tally both\",np.shape(tally_both))\n",
    "print(\"Tally cat units\",np.shape(tally_units_cat))\n",
    "primary_categories = data.primary_categories_per_index()\n",
    "tally_units_cat = np.dot(tally_units_cat, data.labelcat.T) #\n",
    "\n",
    "print(\"Primary categories\",primary_categories)\n",
    "iou = tally_both / (tally_units_cat + tally_labels[np.newaxis,:] - tally_both + 1e-10)\n",
    "print(\"IOU\",np.shape(iou))\n",
    "pciou = np.array([iou * (primary_categories[np.arange(iou.shape[1])] == ci)[np.newaxis, :] for ci in range(len(data.category_names()))])\n",
    "print(data.size)\n",
    "print(\"PCIOU\",np.shape(pciou))\n",
    "primary_categories = data.primary_categories_per_index()\n",
    "label_pciou = pciou.argmax(axis=2)\n",
    "print(\"Label PCIOU\",np.shape(label_pciou))\n",
    "score_pciou = pciou[\n",
    "            np.arange(pciou.shape[0])[:, np.newaxis],\n",
    "            np.arange(pciou.shape[1])[np.newaxis, :],\n",
    "            label_pciou]\n",
    "print(\"Score PCIOU\",np.shape(score_pciou))\n",
    "label_cat = data.labelcat\n",
    "print(primary_categories)\n",
    "print(label_cat)\n",
    "print(np.shape(label_cat))\n",
    "print(len(primary_categories))\n",
    "print(data.name(None,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = features.shape[1] #depth or number of channels (512 for res18 layer 4)\n",
    "size_RF = (settings.IMG_SIZE / features.shape[2], settings.IMG_SIZE / features.shape[3]) #Broden size/ feature map size = (224/7,224,7)\n",
    "fieldmap = ((0, 0), size_RF, size_RF) #((0,0),(32,32),(32,32))\n",
    "print(fieldmap)\n",
    "start = 0\n",
    "end = data.size()\n",
    "print(\"Start %d ,End %d\"%(start,end))\n",
    "pd = SegmentationPrefetcher(data, categories=data.category_names(),\n",
    "                            once=True, batch_size=settings.TALLY_BATCH_SIZE,\n",
    "                                    ahead=settings.TALLY_AHEAD, start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = start\n",
    "img = None\n",
    "img_path = \"\"\n",
    "for batch in pd.batches():\n",
    "    print(count)\n",
    "    for concept_map in batch:\n",
    "        img_index = concept_map['i']\n",
    "        for key,val in concept_map.items():\n",
    "            print(key,val)\n",
    "        count+=1\n",
    "        if(concept_map[\"scene\"]!=[]):\n",
    "            object_img = concept_map['object']\n",
    "            color_img = concept_map[\"color\"]\n",
    "            part_img = concept_map[\"part\"]\n",
    "            scence_img = concept_map[\"scene\"]\n",
    "            img_path = concept_map['fn']\n",
    "#         print(concept_map.keys())\n",
    "#         print(img_index)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_result = fo.tally(features,thresh,savepath=\"tally.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03595145",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1=None\n",
    "for res in tally_result:\n",
    "    if(res[\"unit\"]==1):unit_1 = res\n",
    "        \n",
    "for key,vals in unit_1.items():\n",
    "    print(key,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98172f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "X = Image.open(img_path)\n",
    "fig,ax = plt.subplots(2,1,figsize=(15,15))\n",
    "ax[0].imshow(X)\n",
    "# print(scence_img)\n",
    "print(data.labelcat)\n",
    "print(np.shape(data.labelcat))\n",
    "# ax[1].imshow(object_img.reshape((112,112)))\n",
    "# ax[1].imshow(color_img.reshape((112,112)))\n",
    "# ax[1].imshow(part_img.reshape((112,112)))\n",
    "# ax[1].imshow(scence_img.reshape((112,112)))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
